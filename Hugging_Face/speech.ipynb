{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ix502iv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import argparse\n",
    "import librosa #audio lib\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer #, AutoTokenizer,Wav2Vec2CTCTokenizer\n",
    "\n",
    "#access_token = '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'\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav2vec2_960h_model():\n",
    "  \"\"\"\n",
    "  returns the tokenizer and the model from pretrained tokenizer models\n",
    "  \"\"\"\n",
    "  tokenizer = Wav2Vec2Tokenizer.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "                                                #,use_auth_token=access_token)\n",
    "  model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "                                         #,use_auth_token=access_token)\n",
    "  return tokenizer, model\n",
    "\n",
    "def correct_uppercase_sentence(input_text):\n",
    "  \"\"\"\n",
    "  returns the correct sentence\n",
    "  \"\"\"\n",
    "  sentences = nltk.sent_tokenize(input_text)\n",
    "  return(' '.join([s.replace(s[0],s[0].capitalize(),1) for s in sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr_transcription(tokenizer, model, input_file):\n",
    "  \"\"\"\n",
    "  Returns the transcript of the input auio recording\n",
    "  output: transcribed text\n",
    "  input: hugglingface tokenizer, model, wav file\n",
    "  \"\"\"\n",
    "\n",
    "  #read the file\n",
    "  speech, samplerate = sf.read(input_file)\n",
    "  #make it 1-dimentional\n",
    "  if len(speech.shape)>1:\n",
    "    speech = speech[:,0] + speech[:,1]\n",
    "  #resample to 16kHz\n",
    "  if samplerate != 16000:\n",
    "    speech = librosa.resample(speech, samplerate, 16000)\n",
    "  #tokenize\n",
    "  input_values = tokenizer(speech, return_tensors='pt').input_values\n",
    "  #take logits\n",
    "  logits = model(input_values).logits\n",
    "  #take argmax( find most probable word id)\n",
    "  predicted_ids = torch.argmax(logits, dim=-1)\n",
    "  #get the word from the predicted words ids\n",
    "  transcription = tokenizer.decode(predicted_ids[0])\n",
    "  #output all in uppercase\n",
    "  transcription = correct_uppercase_sentence(transcription.lower())\n",
    "  return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/home/ix502iv/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:746: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_6056/816766423.py:15: FutureWarning: Pass orig_sr=8000, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  speech = librosa.resample(speech, samplerate, 16000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uschulda probably tring these modle on a don stream tusk to be able to use eat for prediction and inferents futa warnig pass original somping rat to eight thousand tuget something reat to six the one dosan six hundred eskiwad argument\n"
     ]
    }
   ],
   "source": [
    "wav_input = \"brian.wav\"\n",
    "tokenizer, model = load_wav2vec2_960h_model()\n",
    "text = asr_transcription(tokenizer, model, wav_input)\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc128987b80414afb03073ef0ac1a5f16932121e6908c8d5ab86fd86be48a1ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
